{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [10, 20, 30, 40, 50],\n",
    "    'min_samples_leaf': [1, 2, 5, 10, 15, 20],\n",
    "    'min_samples_split': [8, 10, 12, 16, 20, 24],\n",
    "    'n_estimators': [100, 200, 300, 400, 500, 1000]\n",
    "}\n",
    "\n",
    "kfold = KFold(n_splits = 4)\n",
    "\n",
    "RF_NewModel = GridSearchCV(estimator = RandomForestModel, param_grid = param_grid, \n",
    "                          cv = kfold, n_jobs = -1, verbose = 2, return_train_score=True)\n",
    "\n",
    "RF_NewModel.fit(X_train_scaled, y_train_scaled);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_NewModel.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions_scaled = RF_NewModel.predict(X_train_scaled)\n",
    "train_predictions = scaler.inverse_transform(train_predictions_scaled)\n",
    "test_predictions_scaled = RF_NewModel.predict(X_test_scaled)\n",
    "test_predictions = scaler.inverse_transform(test_predictions_scaled)\n",
    "\n",
    "Train_MAE = mean_absolute_error(y_train, train_predictions)\n",
    "Train_MSE = mean_squared_error(y_train, train_predictions)\n",
    "Train_RMS = sqrt(mean_squared_error(y_train, train_predictions))\n",
    "Train_R2Score = r2_score(y_train, train_predictions)\n",
    "\n",
    "Test_MAE = mean_absolute_error(y_test, test_predictions)\n",
    "Test_MSE = mean_squared_error(y_test, test_predictions)\n",
    "Test_RMS = sqrt(mean_squared_error(y_test, test_predictions))\n",
    "Test_R2Score = r2_score(y_test, test_predictions)\n",
    "\n",
    "print('Train MAE Value:', Train_MAE)\n",
    "print('Train MSE Value:', Train_MSE)\n",
    "print('Train RMS Value:', Train_RMS)\n",
    "print('Train R2 Score:', Train_R2Score)\n",
    "print('\\n')\n",
    "\n",
    "print('Test MAE Value:', Test_MAE)\n",
    "print('Test MSE Value:', Test_MSE)\n",
    "print('Test RMS Value:', Test_RMS)\n",
    "print('Test R2 Score:', Test_R2Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 20, 10\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.scatter(x = train['State'], y = train['cases'], linewidths = 1, alpha = 0.7, edgecolor = 'k', s = 100, cmap = 'inferno')\n",
    "plt.scatter(x = test['State'], y = test['cases'], linewidths = 1, alpha = 0.7, edgecolor = 'k', s = 100, cmap = 'inferno')\n",
    "plt.scatter(x = train['State'], y = train_predictions, linewidths = 1, alpha = 0.7, edgecolor = 'k', s = 100, cmap = 'inferno')\n",
    "plt.title('Public School Expenditure vs. COVID-19 Case Count Per State', fontsize = 16, fontweight = 'bold')\n",
    "plt.xlabel('State', fontsize = 10, fontweight = 'bold')\n",
    "plt.ylabel('COVID-19 Case Count', fontsize = 10, fontweight = 'bold')\n",
    "\n",
    "plt.legend(['Train Data', 'Test Data', 'Train Predictions'])\n",
    "\n",
    "plt.xticks(rotation = 90)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 20, 10\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.scatter(x = train['State'], y = train['cases'], linewidths = 1, alpha = 0.7, edgecolor = 'k', s = 100, cmap = 'inferno')\n",
    "plt.scatter(x = test['State'], y = test['cases'], linewidths = 1, alpha = 0.7, edgecolor = 'k', s = 100, cmap = 'inferno')\n",
    "plt.scatter(x = test['State'], y = test_predictions, linewidths = 1, alpha = 0.7, edgecolor = 'k', s = 100, cmap = 'inferno')\n",
    "plt.title('Public School Expenditure vs. COVID-19 Case Count Per State', fontsize = 16, fontweight = 'bold')\n",
    "plt.xlabel('State', fontsize = 10, fontweight = 'bold')\n",
    "plt.ylabel('COVID-19 Case Count', fontsize = 10, fontweight = 'bold')\n",
    "\n",
    "plt.legend(['Train Data', 'Test Data', 'Test Predictions'])\n",
    "\n",
    "plt.xticks(rotation = 90)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_accuracy = evaluate(RandomForestModel, X_train_scaled, y_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_accuracy = evaluate(RF_NewModel, X_train_scaled, y_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Improvement of {:0.2f}%.'.format( 100 * (new_accuracy - base_accuracy) / new_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 20, 10\n",
    "\n",
    "plt.figure()\n",
    "sns.distplot((np.array(test_predictions).reshape(-1) - y_test), bins = 51, color = 'b', hist_kws = {'edgecolor':'k'})\n",
    "plt.title('Public School Expenditure Model Accuracy', fontsize = 16, fontweight = 'bold')\n",
    "plt.xlabel('Cases', fontsize = 10, fontweight = 'bold')\n",
    "plt.ylabel('Frequency', fontsize = 10, fontweight = 'bold')\n",
    "\n",
    "plt.show();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
